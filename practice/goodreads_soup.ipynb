{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/katiehuang/Desktop/metis/projects/onl_ds5_project_2/py')\n",
    "from loadpage import get_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create url list (for 19 pages)\n",
    "listopia_base_url=\"https://www.goodreads.com/list/show/2451.I_Saw_the_Movie_Read_the_Book\"\n",
    "\n",
    "listopia_url_list=[listopia_base_url]\n",
    "for i in range(2,20):\n",
    "    url = listopia_base_url + '?page=' + str(i)\n",
    "    listopia_url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create soup_list (19 soup for 19 pages)\n",
    "listopia_soup_list=[]\n",
    "for url in listopia_url_list:\n",
    "    listopia_soup_list.append(get_soup(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listopia_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url for each book from the list (I Saw the Movie & Read the Book) webpages\n",
    "# Try first page (listopia_base_url)\n",
    "\n",
    "base_book_url=\"https://www.goodreads.com/\"\n",
    "book_url_list=[]\n",
    "\n",
    "soup = listopia_soup_list[1]\n",
    "\n",
    "table= soup.find('table', class_=\"tableList js-dataTooltip\")\n",
    "rows = [row for row in table.find_all('tr')]\n",
    "\n",
    "for i in range(100):\n",
    "    book_url = rows[i].find_all('a')[0].get('href')\n",
    "    book_url_list.append(base_book_url+book_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url for each book from the list (I Saw the Movie & Read the Book) webpages\n",
    "# Create a list of url for 1800+ books\n",
    "\n",
    "book_url_list=[]\n",
    "base_book_url=\"https://www.goodreads.com/\"\n",
    "\n",
    "for soup in listopia_soup_list[:-1]:\n",
    "    table= soup.find('table', class_=\"tableList js-dataTooltip\")\n",
    "    rows = [row for row in table.find_all('tr')]\n",
    "\n",
    "    for i in range(100):\n",
    "        book_url = rows[i].find_all('a')[0].get('href')\n",
    "        book_url_list.append(base_book_url+book_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create soup_list for the books\n",
    "\n",
    "book_soup_list=[]\n",
    "for book_url in book_url_list[0:201]:\n",
    "    book_soup = get_soup(book_url)\n",
    "    book_soup_list.append(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_url in book_url_list[201:901]:\n",
    "    book_soup = get_soup(book_url)\n",
    "    book_soup_list.append(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_url in book_url_list[901:]:\n",
    "    book_soup = get_soup(book_url)\n",
    "    book_soup_list.append(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get book data from the book page\n",
    "def get_bookdata(book): # book = soup in book_soup_list\n",
    "    \n",
    "    headers=['book_title', 'author', 'rating_value', 'rating_count', 'review_count', 'page', 'year']\n",
    "    \n",
    "    # Find book title, author, rating_value, rating_count, review_count, page\n",
    "    title = book.find('h1').text.strip('\\n').lstrip()\n",
    "    author = book.find('a', class_=\"authorName\").text\n",
    "    rating_value = float(book.find('span', attrs={'itemprop':'ratingValue'}).text.strip('\\n').lstrip())\n",
    "    rating_count = int(book.find('meta', attrs={'itemprop':'ratingCount'}).get('content'))\n",
    "    review_count = int(book.find('meta', attrs={'itemprop':'reviewCount'}).get('content'))\n",
    "    page = int(book.find('span', attrs={'itemprop':'numberOfPages'}).text.strip(' pages'))\n",
    "\n",
    "    # Find year first published\n",
    "    for div in book.find_all('div', attrs={'id':'details'}):\n",
    "        for row in div.find_all('nobr', class_='greyText'):\n",
    "            year = row.text\n",
    "            year = int(''.join(i for i in year if i.isdigit())[-4:])\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Find earliest year\n",
    "    string = div.find_all('div', class_='row')[1].text\n",
    "    str_clean = string.replace('(',' ').replace(')',' ').split()\n",
    "    year_list = [int(s) for s in str_clean if s.isdigit()]\n",
    "    year = min(year_list)\n",
    "    \n",
    "    \n",
    "    book_dict = dict(zip(headers, [title,\n",
    "                                   author,\n",
    "                                   rating_value,\n",
    "                                   rating_count,\n",
    "                                   review_count,\n",
    "                                   page,\n",
    "                                   year]))\n",
    "    \n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get book data from the book page\n",
    "# Try fixing missing value problem\n",
    "# Try fixing first published year problem (if there's only first published year)\n",
    "\n",
    "\n",
    "def get_bookdata(book): # book = soup in book_soup_list\n",
    "    \n",
    "    headers=['book_title', 'author', 'rating_value', 'rating_count', 'review_count', 'page', 'year']\n",
    "    \n",
    "    # Assign default value\n",
    "    title, author, rating_value, rating_count, review_count, page, year = \\\n",
    "    np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    # Find book title, author, rating_value, rating_count, review_count, page\n",
    "    title = book.find('h1').text.strip('\\n').lstrip()\n",
    "    author = book.find('a', class_=\"authorName\").text\n",
    "    rating_value = float(book.find('span', attrs={'itemprop':'ratingValue'}).text.strip('\\n').lstrip())\n",
    "    rating_count = int(book.find('meta', attrs={'itemprop':'ratingCount'}).get('content'))\n",
    "    review_count = int(book.find('meta', attrs={'itemprop':'reviewCount'}).get('content'))\n",
    "    if book.find('span', attrs={'itemprop':'numberOfPages'}) is not None:\n",
    "        page = int(book.find('span', attrs={'itemprop':'numberOfPages'}).text.strip(' pages'))\n",
    "\n",
    "    # Find year first published\n",
    "    for div in book.find_all('div', attrs={'id':'details'}):\n",
    "        for row in div.find_all('nobr', class_='greyText'):\n",
    "            year = row.text\n",
    "            year = int(''.join(i for i in year if i.isdigit())[-4:])\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Find earliest year\n",
    "    if div.find_all('div', class_='row') != []:\n",
    "        string = div.find_all('div', class_='row')[-1].text\n",
    "        str_clean = string.replace('(',' ').replace(')',' ').split()\n",
    "        year_list = [int(s) for s in str_clean if s.isdigit()]\n",
    "        if year_list != []:\n",
    "            year = min(year_list)\n",
    "    \n",
    "    \n",
    "    book_dict = dict(zip(headers, [title,\n",
    "                                   author,\n",
    "                                   rating_value,\n",
    "                                   rating_count,\n",
    "                                   review_count,\n",
    "                                   page,\n",
    "                                   year]))\n",
    "    \n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Harry Potter #1\n",
    "hp_url = book_url_list[0]\n",
    "hp = book_soup_list[0]\n",
    "get_bookdata(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of book_dict\n",
    "book_data=[]\n",
    "for book_soup in book_soup_list:\n",
    "    book = get_bookdata(book_soup)\n",
    "    book_data.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pd DataFrame of 1800 books!\n",
    "book_df = pd.DataFrame(book_data)\n",
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to pickle file\n",
    "book_df.to_pickle('../dump/book_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
