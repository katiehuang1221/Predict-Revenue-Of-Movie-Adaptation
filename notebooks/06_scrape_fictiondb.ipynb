{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get data of publications (year) for each author on fictionDB.com by selenium.\n",
    "\n",
    "functions used:\n",
    "search(author) from fictiondb.py\n",
    "\n",
    "Added more data on 1/20/2021\n",
    "\n",
    "Output to pickle 'author_book_df'.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/katiehuang/Documents/metis/projects/onl_ds5_project_2/py')\n",
    "from scrape import *\n",
    "import importlib\n",
    "from fictiondb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open automated Chrome with fictionDB webpage\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(\"https://www.fictiondb.com/search/search.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find books survived in the merge and create author list to search on fictionDB\n",
    "# Load 'movie_data','book_data', 'found_book' and merge/concat\n",
    "\n",
    "movie_df = pd.read_pickle('../data/movie_data')\n",
    "book_df = pd.read_pickle('../data/book_data')\n",
    "found_book_df = pd.read_pickle('../data/found_book')\n",
    "overlap_df = pd.merge(book_df, movie_df,left_on='book_title',\\\n",
    "                      right_on='movie_title', how='inner')\n",
    "overlap_df2 = pd.merge(found_book_df, movie_df,left_on='book_title',\\\n",
    "                      right_on='movie_title', how='inner')\n",
    "\n",
    "combined_book_df = pd.concat([overlap_df,overlap_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_book_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of author and remove duplicates by converting to set\n",
    "author_list = list(combined_book_df.author)\n",
    "author_list_set = set(author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(author_list_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list of unique author\n",
    "import pickle\n",
    "with open('../dump/author_list_set', 'wb') as f:\n",
    "    pickle.dump(author_list_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "author_list_set = pd.read_pickle('../dump/author_list_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open automated Chrome with fictionDB webpage\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(\"https://www.fictiondb.com/search/search.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "author_book_list=[]\n",
    "for author in author_list_set:\n",
    "    c += 1\n",
    "    print(c,author)\n",
    "    result = search(author)\n",
    "    author_book_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle\n",
    "import pickle\n",
    "with open('../dump/author_book_list', 'wb') as f:\n",
    "    pickle.dump(author_book_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "author_book_list = pd.read_pickle('../dump/author_book_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran into error, search for the rest of the authors\n",
    "c = len(author_book_list)\n",
    "done_author=[]\n",
    "for dic in author_book_list:\n",
    "    for key, value in dic.items():\n",
    "        print(key)\n",
    "        done_author.append(key)\n",
    "        \n",
    "# authors still need to be looked up        \n",
    "left_author_set = author_list_set.difference(set(done_author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '../py/fictiondb.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in left_author_set:\n",
    "    c += 1\n",
    "    print(c,author)\n",
    "    result = search(author)\n",
    "    author_book_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(author_book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle\n",
    "import pickle\n",
    "with open('../dump/author_book_list', 'wb') as f:\n",
    "    pickle.dump(author_book_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create DataFrame of author and publication years and pickle\n",
    "author_book_df = pd.DataFrame(author_book_list_test)\n",
    "author_book_df.to_pickle('../dump/author_book_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase author_book data (1/20/2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 1/20/2021\n",
    "# Load data from the second scrape of book data\n",
    "author_book_df1 = pd.read_pickle('../dump/author_book_data')\n",
    "author_book_df2 = pd.read_pickle('../dump/author_book_data_add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna Todd</td>\n",
       "      <td>[2020, 2018, 2018, 2017, 2017, 2016, 2016, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Flinn</td>\n",
       "      <td>[2020, 2019, 2017, 2015, 2015, 2013, 2012, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James Fenimore Cooper</td>\n",
       "      <td>[2017, 2012, 2012, 2010, 2009, 2006, 1841, 1826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy Daws</td>\n",
       "      <td>[2020, 2019, 2019, 2018, 2018, 2018, 2018, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Bellairs</td>\n",
       "      <td>[2020, 2015, 2009, 2004, 2004, 2004, 2004, 200...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author                                              years\n",
       "0              Anna Todd  [2020, 2018, 2018, 2017, 2017, 2016, 2016, 201...\n",
       "1             Alex Flinn  [2020, 2019, 2017, 2015, 2015, 2013, 2012, 201...\n",
       "2  James Fenimore Cooper   [2017, 2012, 2012, 2010, 2009, 2006, 1841, 1826]\n",
       "3               Amy Daws  [2020, 2019, 2019, 2018, 2018, 2018, 2018, 201...\n",
       "4          John Bellairs  [2020, 2015, 2009, 2004, 2004, 2004, 2004, 200..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge two author_book_df2\n",
    "author_book_df = pd.concat([author_book_df1,author_book_df2])\n",
    "author_book_df.to_pickle('../data/author_book_data')\n",
    "author_book_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
