{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get data of actors from IMDB page.\n",
    "Import movie_data for actor and link_s and scrape the actors pages.\n",
    "For each actor, find list of movies and scrape movie pages for brief info.\n",
    "\n",
    "functions used:\n",
    "get_soup(url) from scrape.py\n",
    "get_movie_brief(soup) from get_movie.py\n",
    "\n",
    "Output to pickle 'actor_data'.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/katiehuang/Documents/metis/projects/onl_ds5_project_2/py')\n",
    "from scrape import *\n",
    "from get_movie import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 'movie'\n",
    "movie_df = pd.read_pickle('../data/movie_data_adaptation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of actor/link from the 2000 movies\n",
    "star_list = []\n",
    "for star in movie_df.star:\n",
    "    star_list += star\n",
    "star_df = pd.DataFrame(star_list)\n",
    "\n",
    "star_link_list = []\n",
    "for star_link in movie_df.link_s:\n",
    "    star_link_list += star_link\n",
    "star_link_df = pd.DataFrame(star_link_list)\n",
    "\n",
    "# Combine in to one df\n",
    "star_df['link_s'] = star_link_df\n",
    "star_df.columns = ['star','link_s']\n",
    "star_df = star_df.drop_duplicates(subset=['star'])\n",
    "star_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create actor_link_dict\n",
    "actor_link_dict = star_df.set_index('star').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of movie_dict for each actor\n",
    "actor_film_list = []\n",
    "\n",
    "base_url = \"https://www.imdb.com\"\n",
    "c = 0 # to check scraping progress\n",
    "\n",
    "for actor in actor_link_dict:\n",
    "    c += 1\n",
    "    print(c, actor)\n",
    "    actor_url = base_url + actor_link_dict[actor][0]\n",
    "    actor_soup = get_soup(actor_url)\n",
    "    \n",
    "    # actor or actress\n",
    "    actor_head = actor_soup.find('div', id=\"filmo-head-actor\")\n",
    "    if actor_head is None:\n",
    "        actor_head = actor_soup.find('div', id=\"filmo-head-actress\")\n",
    "    \n",
    "    films = actor_head.findNext('div')\n",
    "\n",
    "    for film in films:\n",
    "        movie = film.find('a')\n",
    "        if type(movie) != int:\n",
    "            movie_title = movie.text\n",
    "            movie_link = movie.get('href')\n",
    "            movie_soup = get_soup(base_url + movie_link)\n",
    "\n",
    "            detail = get_movie_brief_actor(actor,movie_soup)\n",
    "            actor_film_list.append(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create actor_df and save pickle as 'actor_data'\n",
    "actor_df = pd.DataFrame(actor_film_list)\n",
    "actor_df.to_pickle('../data/actor_data')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
