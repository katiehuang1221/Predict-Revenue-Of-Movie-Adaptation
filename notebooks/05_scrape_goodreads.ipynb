{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Get data of books made into films based on 2 listopia \"book to movie lists\" on goodreads.\n",
    "\n",
    "Scrape search result pages for the book link to individual book page.\n",
    "Scrape book pages\n",
    "\n",
    "Ouput to pickle 'book_data'\n",
    "\n",
    "2. Use selenium to search for 'movie_title' on goodreads.\n",
    "\n",
    "functions used: \n",
    "get_soup(url) from scrape.py\n",
    "get_book_data(book) from get_book.py\n",
    "search_goodreads(movie_title) from get_book.py\n",
    "\n",
    "Output to pickle 'found_book'.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/katiehuang/Documents/metis/projects/onl_ds5_project_2/py')\n",
    "from scrape import *\n",
    "from get_book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scrape from Listopia lists using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create url list of the search results (19 pages)\n",
    "# first list: (I Saw the Movie & Read the Book)\n",
    "\n",
    "listopia_base_url=\"https://www.goodreads.com/list/show/2451.I_Saw_the_Movie_Read_the_Book\"\n",
    "\n",
    "listopia_url_list=[listopia_base_url]\n",
    "for i in range(2,20):\n",
    "    url = listopia_base_url + '?page=' + str(i)\n",
    "    listopia_url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create soup_list (19 soup for 19 pages)\n",
    "listopia_soup_list=[]\n",
    "for url in listopia_url_list:\n",
    "    listopia_soup_list.append(get_soup(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url for each book from the list (I Saw the Movie & Read the Book) webpages\n",
    "# Try first page (listopia_base_url)\n",
    "\n",
    "base_book_url=\"https://www.goodreads.com/\"\n",
    "book_url_list=[]\n",
    "\n",
    "soup = listopia_soup_list[1]\n",
    "\n",
    "table= soup.find('table', class_=\"tableList js-dataTooltip\")\n",
    "rows = [row for row in table.find_all('tr')]\n",
    "\n",
    "for i in range(100):\n",
    "    book_url = rows[i].find_all('a')[0].get('href')\n",
    "    book_url_list.append(base_book_url+book_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url for each book from the list webpages\n",
    "# Create a list of url for 1800+ books\n",
    "\n",
    "book_url_list=[]\n",
    "base_book_url=\"https://www.goodreads.com/\"\n",
    "\n",
    "for soup in listopia_soup_list[:-1]:\n",
    "    table= soup.find('table', class_=\"tableList js-dataTooltip\")\n",
    "    rows = [row for row in table.find_all('tr')]\n",
    "\n",
    "    for i in range(100):\n",
    "        book_url = rows[i].find_all('a')[0].get('href')\n",
    "        book_url_list.append(base_book_url+book_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create soup_list for the books\n",
    "\n",
    "book_soup_list=[]\n",
    "for book_url in book_url_list:\n",
    "    book_soup = get_soup(book_url)\n",
    "    book_soup_list.append(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Harry Potter #1\n",
    "hp_url = book_url_list[0]\n",
    "hp = book_soup_list[0]\n",
    "get_book_data(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of book_dict\n",
    "book_data=[]\n",
    "for book_soup in book_soup_list:\n",
    "    book = get_book_data(book_soup)\n",
    "    book_data.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pd DataFrame of 1800 books!\n",
    "book_df = pd.DataFrame(book_data)\n",
    "book_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to pickle file\n",
    "book_df.to_pickle('../data/book_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search movie title on goodreads using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in movie_data picke file\n",
    "movie_df = pd.read_pickle('../data/movie_data')\n",
    "book_df = pd.read_pickle('../data/book_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = list(movie_df.movie_title)\n",
    "book_list = list(book_df.book_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_book: movies that do not have a matching book\n",
    "need_book_pre = list(set(movie_list).difference(set(book_list)))\n",
    "need_book = [book.replace('&','and').replace(\":\",'') for book in need_book_pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append search result (book_dict) to the list found_book\n",
    "\n",
    "found_book=[]\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "for movie in need_book:\n",
    "    result = search_goodreads(movie)\n",
    "    found_book.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list to pd.DataFrame and pickle\n",
    "found_book_df = pd.DataFrame(found_book)\n",
    "found_book_df.to_pickle('../data/found_book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
