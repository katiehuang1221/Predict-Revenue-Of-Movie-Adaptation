{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create url list (for 19 pages)\n",
    "listopia_base_url=\"https://www.goodreads.com/list/show/2451.I_Saw_the_Movie_Read_the_Book\"\n",
    "\n",
    "listopia_url_list=[listopia_base_url]\n",
    "for i in range(2,20):\n",
    "    url = listopia_base_url + '?page=' + str(i)\n",
    "    listopia_url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create soup_list (19 soup for 19 pages)\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    return soup\n",
    "\n",
    "listopia_soup_list=[]\n",
    "for url in listopia_url_list:\n",
    "    listopia_soup_list.append(get_soup(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listopia_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url for each book from the list (I Saw the Movie & Read the Book) webpages\n",
    "# Try first page (listopia_base_url)\n",
    "\n",
    "base_book_url=\"https://www.goodreads.com/\"\n",
    "book_url_list=[]\n",
    "\n",
    "soup = listopia_soup_list[1]\n",
    "\n",
    "table= soup.find('table', class_=\"tableList js-dataTooltip\")\n",
    "rows = [row for row in table.find_all('tr')]\n",
    "\n",
    "for i in range(100):\n",
    "    book_url = rows[i].find_all('a')[0].get('href')\n",
    "    book_url_list.append(base_book_url+book_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find url for each book from the list (I Saw the Movie & Read the Book) webpages\n",
    "# Create a list of url for 1800+ books\n",
    "\n",
    "book_url_list=[]\n",
    "base_book_url=\"https://www.goodreads.com/\"\n",
    "\n",
    "for soup in listopia_soup_list[:-1]:\n",
    "    table= soup.find('table', class_=\"tableList js-dataTooltip\")\n",
    "    rows = [row for row in table.find_all('tr')]\n",
    "\n",
    "    for i in range(100):\n",
    "        book_url = rows[i].find_all('a')[0].get('href')\n",
    "        book_url_list.append(base_book_url+book_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create soup_list for the books\n",
    "\n",
    "book_soup_list=[]\n",
    "for book_url in book_url_list[0:201]:\n",
    "    book_soup = get_soup(book_url)\n",
    "    book_soup_list.append(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_url in book_url_list[201:901]:\n",
    "    book_soup = get_soup(book_url)\n",
    "    book_soup_list.append(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_url in book_url_list[901:]:\n",
    "    book_soup = get_soup(book_url)\n",
    "    book_soup_list.append(book_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_soup_list.txt','w') as f:\n",
    "    f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-159415ee1006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbook_soup_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dump/book_soup_list'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_pickle'"
     ]
    }
   ],
   "source": [
    "book_soup_list.to_pickle('../dump/book_soup_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump book_soup_list to pickle\n",
    "import pickle\n",
    "file_name = 'book_soup_list.pkl'\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(book_soup_list, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28672\n",
      "36864\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import resource\n",
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "max_rec = 0x9000\n",
    "sys.setrecursionlimit(max_rec)\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_soup_list.pkl', 'wb') as handle:\n",
    "    pickle.dump(book_soup_list, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get movie data from search result pages\n",
    "def get_bookdata(book): # book = soup in book_soup_list\n",
    "    \n",
    "    headers=['book_title', 'author', 'rating_value', 'rating_count', 'review_count', 'page', 'year']\n",
    "    \n",
    "    # Find book title, author, rating_value, rating_count, review_count, page\n",
    "    title = book.find('h1').text.strip('\\n').lstrip()\n",
    "    author = book.find('a', class_=\"authorName\").text\n",
    "    rating_value = float(book.find('span', attrs={'itemprop':'ratingValue'}).text.strip('\\n').lstrip())\n",
    "    rating_count = int(book.find('meta', attrs={'itemprop':'ratingCount'}).get('content'))\n",
    "    review_count = int(book.find('meta', attrs={'itemprop':'reviewCount'}).get('content'))\n",
    "    page = int(book.find('span', attrs={'itemprop':'numberOfPages'}).text.strip(' pages'))\n",
    "\n",
    "    # Find year first published\n",
    "    for div in book.find_all('div', attrs={'id':'details'}):\n",
    "        for row in div.find_all('nobr', class_='greyText'):\n",
    "            year = row.text\n",
    "            year = int(''.join(i for i in year if i.isdigit())[-4:])\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Find earliest year\n",
    "    string = div.find_all('div', class_='row')[1].text\n",
    "    str_clean = string.replace('(',' ').replace(')',' ').split()\n",
    "    year_list = [int(s) for s in str_clean if s.isdigit()]\n",
    "    year = min(year_list)\n",
    "    \n",
    "    \n",
    "    book_dict = dict(zip(headers, [title,\n",
    "                                   author,\n",
    "                                   rating_value,\n",
    "                                   rating_count,\n",
    "                                   review_count,\n",
    "                                   page,\n",
    "                                   year]))\n",
    "    \n",
    "    return book_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Harry Potter #1\n",
    "hp_url = book_url_list[0]\n",
    "hp = book_soup_list[0]\n",
    "get_bookdata(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of book_dict\n",
    "book_data=[]\n",
    "for book_soup in book_soup_list:\n",
    "    book = get_bookdata(book_soup)\n",
    "    book_data.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_url_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bookdata(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data=[]\n",
    "for book_soup in book_soup_list[:8]:\n",
    "    book = get_bookdata(book_soup)\n",
    "    book_data.append(book)\n",
    "book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url=\"https://www.goodreads.com/list/show/2451.I_Saw_the_Movie_Read_the_Book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table= soup.find('table', class_=\"tableList js-dataTooltip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [row for row in table.find_all('tr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[1].find_all('a')[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[1].find_all('a')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_url=\"https://www.goodreads.com/book/show/3.Harry_Potter_and_the_Sorcerer_s_Stone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_soup=get_soup(hp_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = hp_soup.find('h1').text.strip('\\n').lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = hp_soup.find('a', class_=\"authorName\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_value = float(hp_soup.find('span', attrs={'itemprop':'ratingValue'}).text.strip('\\n').lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_count = int(hp_soup.find('meta', attrs={'itemprop':'ratingCount'}).get('content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = int(hp_soup.find('span', attrs={'itemprop':'numberOfPages'}).text.strip(' pages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in hp_soup.find_all('div', attrs={'id':'details'}):\n",
    "#     print(div)\n",
    "    for row in div.find_all('div', class_='row'):\n",
    "        print('hi')\n",
    "        print(row)\n",
    "        row.find_all('nobr', class_='greyText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in hp_soup.find_all('div', attrs={'id':'details'}):\n",
    "#     print(div)\n",
    "    for row in div.find_all('div', class_='row'):\n",
    "        print('hi')\n",
    "        print(row)\n",
    "        row.find_all('div', class_='row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div.find_all('div', class_='row')[1].text.partition('\\n')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in hp_soup.find_all('div', attrs={'id':'details'}):\n",
    "    for row in div.find_all('nobr', class_='greyText'):\n",
    "        year = row.text\n",
    "        year = int(''.join(i for i in year if i.isdigit())[-4:])\n",
    "    if year is None:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = div.find_all('div', class_='row')[1].text.partition('\\n')[2]\n",
    "str = div.find_all('div', class_='row')[1].text\n",
    "str_clean = str.replace('(',' ').replace(')',' ').split()\n",
    "year_list = [int(s) for s in str_clean if s.isdigit()]\n",
    "year = min(year_list)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div.find_all('div', class_='row')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str = str.replace('(',' ').replace(')',' ').split()\n",
    "[int(s) for s in str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = \"(first published June 26th 1997)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.strip('(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.strip('(').strip(')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.strip('(').strip(')').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
